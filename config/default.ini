LLAMA_CONFIG_VERSION = 1

[*]
ubatch-size = 512
ctx-size = 131000
batch-size = 2048
split-mode = row
cache-reuse = 256
tensor-split = 70,30
top-p = 0.95
seed = 2

[gemma-3-1b-it-Q4_K_M]
ctx-size = 0

