LLAMA_CONFIG_VERSION = 1

[*]
ctx-size = 131000
batch-size = 2048
ubatch-size = 512
top-p = 0.95
seed = 2
cache-reuse = 64
main-gpu = 1
split-mode = row
warmup = off

[gemma-3-1b-it-Q4_K_M]
ctx-size = 0

