import { TooltipContent } from "./tooltip-config.types";

export const loraTooltips: Record<string, TooltipContent> = {
  lora: {
    title: "LoRA Path",
    description: "Path to LoRA (Low-Rank Adaptation) adapter file.",
    recommendedValue: "File path to .gguf LoRA file",
    effectOnModel: "Applies LoRA adapter to modify model behavior and specialize it.",
    whenToAdjust: "Use when you want to fine-tune model for specific tasks or styles.",
  },
  lora_scaled: {
    title: "LoRA Scaled",
    description: "Path and scale for LoRA adapter in format path:scale.",
    recommendedValue: "e.g., adapter.gguf:1.0",
    effectOnModel: "Applies LoRA with specified scaling factor.",
    whenToAdjust: "Use to control LoRA influence strength.",
  },
  control_vector: {
    title: "Control Vector",
    description: "Path to control vector for steering model behavior.",
    recommendedValue: "File path to control vector",
    effectOnModel: "Steers model generation in specific directions or styles.",
    whenToAdjust: "Use for fine-grained control over output style or content.",
  },
  control_vector_scaled: {
    title: "Control Vector Scaled",
    description: "Control vector with scale in format path:scale.",
    recommendedValue: "e.g., vector.gguf:1.5",
    effectOnModel: "Applies control vector with specified strength.",
    whenToAdjust: "Adjust scale to control steering intensity.",
  },
  control_vector_layer_range: {
    title: "Control Vector Layer Range",
    description: "Layer range for control vector application.",
    recommendedValue: "e.g., 0,32",
    effectOnModel: "Limits control vector to specific layers.",
    whenToAdjust: "Restrict control to specific layers for targeted effects.",
  },
  model_draft: {
    title: "Model Draft",
    description: "Path to draft model for speculative decoding.",
    recommendedValue: "File path to draft model",
    effectOnModel: "Uses smaller, faster draft model for speculative decoding.",
    whenToAdjust: "Use for faster generation with minimal quality loss.",
  },
  model_url_draft: {
    title: "Model URL Draft",
    description: "URL to download draft model.",
    recommendedValue: "URL to draft model",
    effectOnModel: "Downloads draft model from URL for speculative decoding.",
    whenToAdjust: "Use when draft model needs to be downloaded.",
  },
  ctx_size_draft: {
    title: "Context Size Draft",
    description: "Context size for draft model in tokens.",
    recommendedValue: "512 - 16384 (default: 0)",
    effectOnModel: "Sets context window for draft model.",
    whenToAdjust: "Match to draft model's capabilities.",
  },
  threads_draft: {
    title: "Threads Draft",
    description: "Number of threads for draft model. -1 uses auto.",
    recommendedValue: "-1 or 1-32 (default: -1)",
    effectOnModel: "Controls parallelism for draft model processing.",
    whenToAdjust: "Adjust based on CPU cores and performance needs.",
  },
  threads_batch_draft: {
    title: "Threads Batch Draft",
    description: "Batch threads for draft model.",
    recommendedValue: "-1 or 1-32 (default: -1)",
    effectOnModel: "Controls batching parallelism for draft model.",
    whenToAdjust: "Adjust for optimal batch processing performance.",
  },
  draft_max: {
    title: "Draft Max",
    description: "Maximum number of draft tokens to generate.",
    recommendedValue: "1 - 64 (default: 16)",
    effectOnModel: "Limits speculative decoding draft length.",
    whenToAdjust: "Adjust based on acceptance rate and performance.",
  },
  draft_min: {
    title: "Draft Min",
    description: "Minimum number of draft tokens to generate.",
    recommendedValue: "1 - 32 (default: 5)",
    effectOnModel: "Ensures minimum draft length for speculative decoding.",
    whenToAdjust: "Set based on acceptance characteristics.",
  },
  draft_p_min: {
    title: "Draft P Min",
    description: "Minimum probability threshold for draft tokens.",
    recommendedValue: "0.0 - 0.5 (default: 0.05)",
    effectOnModel: "Filters low-probability draft tokens.",
    whenToAdjust: "Increase to improve draft quality.",
  },
  cache_type_k_draft: {
    title: "Cache Type K Draft",
    description: "Cache type for draft model K matrices.",
    recommendedValue: "e.g., f16, q8_0",
    effectOnModel: "Controls cache precision for draft model keys.",
    whenToAdjust: "Choose based on memory vs quality tradeoff.",
  },
  cache_type_v_draft: {
    title: "Cache Type V Draft",
    description: "Cache type for draft model V matrices.",
    recommendedValue: "e.g., f16, q8_0",
    effectOnModel: "Controls cache precision for draft model values.",
    whenToAdjust: "Choose based on memory vs quality tradeoff.",
  },
  cpu_moe_draft: {
    title: "CPU MoE Draft",
    description: "Whether draft model MoE runs on CPU. 0=off, 1=on.",
    recommendedValue: "0 or 1 (default: 0)",
    effectOnModel: "Forces draft model MoE on CPU.",
    whenToAdjust: "Use when GPU memory is constrained.",
  },
  n_cpu_moe_draft: {
    title: "N CPU MoE Draft",
    description: "Number of MoE experts for draft on CPU.",
    recommendedValue: "0 - 32 (default: 0)",
    effectOnModel: "Limits MoE experts processed on CPU for draft model.",
    whenToAdjust: "Adjust based on CPU capacity.",
  },
  n_gpu_layers_draft: {
    title: "N GPU Layers Draft",
    description: "GPU layers for draft model. -1 uses auto.",
    recommendedValue: "-1 or 0-n (default: -1)",
    effectOnModel: "Controls draft model GPU offloading.",
    whenToAdjust: "Adjust based on available VRAM.",
  },
  device_draft: {
    title: "Device Draft",
    description: "Device for draft model.",
    recommendedValue: "e.g., cuda, metal, cpu",
    effectOnModel: "Selects compute backend for draft model.",
    whenToAdjust: "May differ from main model for optimization.",
  },
  spec_replace: {
    title: "Spec Replace",
    description: "Speculative decoding replacement strategy.",
    recommendedValue: "Replacement strategy",
    effectOnModel: "Controls how tokens are replaced during speculation.",
    whenToAdjust: "Configure based on speculative decoding behavior.",
  },
};