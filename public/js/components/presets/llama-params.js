/**
 * Llama Parameters Definition
 * Contains all parameter definitions for llama.cpp
 * Loaded lazily when presets page is accessed
 */

const LLAMA_PARAMS = [
  {
    key: "ctx-size",
    iniKey: "ctxSize",
    label: "Context Size",
    type: "number",
    default: 0,
    min: 0,
    max: 32768,
    step: 512,
    group: "core",
    description: "Size of the prompt context (0 = loaded from model)",
  },
  {
    key: "batch-size",
    iniKey: "batchSize",
    label: "Batch Size",
    type: "number",
    default: 2048,
    min: 1,
    max: 65536,
    step: 1,
    group: "core",
    description: "Logical maximum batch size",
  },
  {
    key: "ubatch-size",
    iniKey: "ubatchSize",
    label: "Micro Batch Size",
    type: "number",
    default: 512,
    min: 1,
    max: 65536,
    step: 1,
    group: "core",
    description: "Physical maximum batch size",
  },
  {
    key: "n-predict",
    iniKey: "nPredict",
    label: "Max Tokens",
    type: "number",
    default: -1,
    min: -1,
    max: 2147483647,
    step: 1,
    group: "core",
    description: "Number of tokens to predict (-1 = infinite)",
  },
  {
    key: "threads",
    iniKey: "threads",
    label: "Threads",
    type: "number",
    default: 0,
    min: 0,
    max: 256,
    step: 1,
    group: "hardware",
    description: "Number of CPU threads (0 = all CPUs)",
  },
  {
    key: "threads-batch",
    iniKey: "threadsBatch",
    label: "Threads (Batch)",
    type: "number",
    default: 0,
    min: 0,
    max: 256,
    step: 1,
    group: "hardware",
    description: "Threads for batch and prompt processing (0 = same as --threads)",
  },
  {
    key: "n-gpu-layers",
    iniKey: "nGpuLayers",
    label: "GPU Layers",
    type: "number",
    default: -1,
    min: -1,
    max: 256,
    step: 1,
    group: "hardware",
    description: "Max layers to store in VRAM (-1=auto, 0=CPU)",
  },
  {
    key: "split-mode",
    iniKey: "splitMode",
    label: "Split Mode",
    type: "select",
    default: "layer",
    options: ["none", "layer", "row"],
    group: "hardware",
    description: "How to split model across multiple GPUs",
  },
  {
    key: "tensor-split",
    iniKey: "tensorSplit",
    label: "Tensor Split",
    type: "text",
    default: "",
    group: "hardware",
    description: "Fraction of model to offload to each GPU (comma-separated)",
  },
  {
    key: "main-gpu",
    iniKey: "mainGpu",
    label: "Main GPU",
    type: "number",
    default: 0,
    min: 0,
    max: 8,
    step: 1,
    group: "hardware",
    description: "GPU index to use for model/KV",
  },
  {
    key: "temp",
    iniKey: "temperature",
    label: "Temperature",
    type: "number",
    default: 0.8,
    min: 0,
    max: 2,
    step: 0.01,
    group: "sampling",
    description: "Sampling temperature",
  },
  {
    key: "top-k",
    iniKey: "topK",
    label: "Top K",
    type: "number",
    default: 40,
    min: 0,
    max: 1000,
    step: 1,
    group: "sampling",
    description: "Top-k sampling (0 = disabled)",
  },
  {
    key: "top-p",
    iniKey: "topP",
    label: "Top P",
    type: "number",
    default: 0.9,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "Top-p sampling (0-1, 1 = disabled)",
  },
  {
    key: "min-p",
    iniKey: "minP",
    label: "Min P",
    type: "number",
    default: 0.1,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "Minimum probability for token selection (0-1)",
  },
  {
    key: "xtc-probability",
    iniKey: "xtcProbability",
    label: "XTC Probability",
    type: "number",
    default: 0,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "XTC sampling probability (0 = disabled)",
  },
  {
    key: "xtc-threshold",
    iniKey: "xtcThreshold",
    label: "XTC Threshold",
    type: "number",
    default: 0.1,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "XTC threshold for low probability tokens",
  },
  {
    key: "typical-p",
    iniKey: "typicalP",
    label: "Typical P",
    type: "number",
    default: 1,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "Typical probability mass (1 = disabled)",
  },
  {
    key: "repeat-last-n",
    iniKey: "repeatLastN",
    label: "Repeat Last N",
    type: "number",
    default: 64,
    min: -1,
    max: 131072,
    step: 1,
    group: "sampling",
    description: "Last N tokens to consider for penalty (-1 = context size)",
  },
  {
    key: "repeat-penalty",
    iniKey: "repeatPenalty",
    label: "Repeat Penalty",
    type: "number",
    default: 1,
    min: 0,
    max: 2,
    step: 0.01,
    group: "sampling",
    description: "Penalty for repeated tokens (1 = disabled)",
  },
  {
    key: "presence-penalty",
    iniKey: "presencePenalty",
    label: "Presence Penalty",
    type: "number",
    default: 0,
    min: 0,
    max: 2,
    step: 0.01,
    group: "sampling",
    description: "Presence penalty for new tokens",
  },
  {
    key: "frequency-penalty",
    iniKey: "frequencyPenalty",
    label: "Frequency Penalty",
    type: "number",
    default: 0,
    min: 0,
    max: 2,
    step: 0.01,
    group: "sampling",
    description: "Frequency-based penalty for repeated tokens",
  },
  {
    key: "dry-multiplier",
    iniKey: "dryMultiplier",
    label: "DRY Multiplier",
    type: "number",
    default: 0,
    min: 0,
    max: 10,
    step: 0.1,
    group: "sampling",
    description: "DRY repetition penalty multiplier (0 = disabled)",
  },
  {
    key: "dry-base",
    iniKey: "dryBase",
    label: "DRY Base",
    type: "number",
    default: 1.75,
    min: 0,
    max: 10,
    step: 0.01,
    group: "sampling",
    description: "DRY base value",
  },
  {
    key: "dry-allowed-length",
    iniKey: "dryAllowedLength",
    label: "DRY Allowed Length",
    type: "number",
    default: 2,
    min: 1,
    max: 10,
    step: 1,
    group: "sampling",
    description: "DRY allowed length",
  },
  {
    key: "dry-penalty-last-n",
    iniKey: "dryPenaltyLastN",
    label: "DRY Penalty Last N",
    type: "number",
    default: -1,
    min: -1,
    max: 131072,
    step: 1,
    group: "sampling",
    description: "DRY lookback window (-1 = context size)",
  },
  {
    key: "mirostat",
    iniKey: "mirostat",
    label: "Mirostat",
    type: "number",
    default: 0,
    min: 0,
    max: 2,
    step: 1,
    group: "sampling",
    description: "Mirostat sampling (0=disabled, 1=Mirostat, 2=Mirostat 2.0)",
  },
  {
    key: "mirostat-lr",
    iniKey: "mirostatLr",
    label: "Mirostat LR",
    type: "number",
    default: 0.1,
    min: 0,
    max: 1,
    step: 0.01,
    group: "sampling",
    description: "Mirostat learning rate",
  },
  {
    key: "mirostat-ent",
    iniKey: "mirostatEnt",
    label: "Mirostat Entropy",
    type: "number",
    default: 5,
    min: 0,
    max: 10,
    step: 0.01,
    group: "sampling",
    description: "Mirostat target entropy",
  },
  {
    key: "penalty-prompt",
    iniKey: "penaltyPrompt",
    label: "Penalty Prompt",
    type: "text",
    default: "",
    group: "sampling",
    description: "Penalty prompt tokens (comma-separated token IDs)",
  },
  {
    key: "no-pen-np",
    iniKey: "noPenNp",
    label: "No Penalty for NP",
    type: "boolean",
    default: false,
    group: "sampling",
    description: "Disable penalties for non-prompt tokens",
  },
  {
    key: "distractor",
    iniKey: "distractor",
    label: "Distractor",
    type: "number",
    default: 0,
    min: 0,
    max: 32768,
    step: 1,
    group: "sampling",
    description: "Distractor sequence length (0 = disabled)",
  },
  {
    key: "anti-prompt",
    iniKey: "antiPrompt",
    label: "Anti-Prompt",
    type: "text",
    default: "",
    group: "behavior",
    description: "Token(s) to stop generation (comma-separated)",
  },
  {
    key: "logits-filter",
    iniKey: "logitsFilter",
    label: "Logits Filter",
    type: "text",
    default: "",
    group: "behavior",
    description: "Comma-separated token IDs to filter from logits",
  },
  {
    key: "grammar",
    iniKey: "grammar",
    label: "Grammar",
    type: "text",
    default: "",
    group: "behavior",
    description: "BNF grammar file path",
  },
  {
    key: "grammar-file",
    iniKey: "grammarFile",
    label: "Grammar File",
    type: "text",
    default: "",
    group: "behavior",
    description: "Grammar file path",
  },
  {
    key: "cfg-negative-prompt",
    iniKey: "cfgNegativePrompt",
    label: "CFG Negative Prompt",
    type: "text",
    default: "",
    group: "behavior",
    description: "Negative prompt for classifier-free guidance",
  },
  {
    key: "cfg-scale",
    iniKey: "cfgScale",
    label: "CFG Scale",
    type: "number",
    default: 1,
    min: 0,
    max: 20,
    step: 0.1,
    group: "behavior",
    description: "Classifier-free guidance scale (1 = disabled)",
  },
  {
    key: "cfg-negative-prompt-auto",
    iniKey: "cfgNegativePromptAuto",
    label: "Auto CFG Negative",
    type: "boolean",
    default: false,
    group: "behavior",
    description: "Auto-generate negative prompt for CFG",
  },
  {
    key: "chat-template",
    iniKey: "chatTemplate",
    label: "Chat Template",
    type: "text",
    default: "",
    group: "behavior",
    description: "Chat template file path (or auto-detect from model)",
  },
  {
    key: "simple-io",
    iniKey: "simpleIo",
    label: "Simple I/O",
    type: "boolean",
    default: false,
    group: "behavior",
    description: "Use simplified I/O (reduces overhead)",
  },
  {
    key: "multiline-input",
    iniKey: "multilineInput",
    label: "Multiline Input",
    type: "boolean",
    default: false,
    group: "behavior",
    description: "Allow multiline user input (EOF to submit)",
  },
  {
    key: "use-color",
    iniKey: "useColor",
    label: "Use Color",
    type: "boolean",
    default: false,
    group: "behavior",
    description: "Use color output",
  },
  {
    key: "interactive",
    iniKey: "interactive",
    label: "Interactive",
    type: "boolean",
    default: false,
    group: "behavior",
    description: "Run in interactive mode",
  },
  {
    key: "prompt-cache-file",
    iniKey: "promptCacheFile",
    label: "Prompt Cache File",
    type: "text",
    default: "",
    group: "context",
    description: "Prompt cache file path",
  },
  {
    key: "prompt-cache-all",
    iniKey: "promptCacheAll",
    label: "Cache All Prompts",
    type: "boolean",
    default: false,
    group: "context",
    description: "Cache all evaluated prompts",
  },
  {
    key: "prompt-cache-ro",
    iniKey: "promptCacheRo",
    label: "Cache Read-Only",
    type: "boolean",
    default: false,
    group: "context",
    description: "Use prompt cache in read-only mode",
  },
  {
    key: "no-prompt-cache",
    iniKey: "noPromptCache",
    label: "No Prompt Cache",
    type: "boolean",
    default: false,
    group: "context",
    description: "Disable prompt cache",
  },
  {
    key: "embeddings",
    iniKey: "embeddings",
    label: "Embeddings",
    type: "boolean",
    default: true,
    group: "context",
    description: "Enable embeddings endpoint",
  },
  {
    key: "embedding-only",
    iniKey: "embeddingOnly",
    label: "Embedding Only",
    type: "boolean",
    default: false,
    group: "context",
    description: "Only run embedding inference",
  },
  {
    key: "pooling",
    iniKey: "pooling",
    label: "Pooling",
    type: "select",
    default: "none",
    options: ["none", "mean", "cls"],
    group: "context",
    description: "Position pooling type for embeddings",
  },
  {
    key: "n-draft",
    iniKey: "nDraft",
    label: "Speculative Drafts",
    type: "number",
    default: 4,
    min: 0,
    max: 32,
    step: 1,
    group: "speculative",
    description: "Number of speculative drafts (0 = disabled)",
  },
  {
    key: "n-seq-batch",
    iniKey: "nSeqBatch",
    label: "Sequence Batch",
    type: "number",
    default: 2048,
    min: 1,
    max: 65536,
    step: 1,
    group: "performance",
    description: "Maximum number of sequences to batch",
  },
  {
    key: "n-parallel",
    iniKey: "nParallel",
    label: "Parallel Requests",
    type: "number",
    default: 1,
    min: 1,
    max: 1024,
    step: 1,
    group: "performance",
    description: "Number of parallel requests to handle",
  },
  {
    key: "cont-batching",
    iniKey: "contBatching",
    label: "Continuous Batching",
    type: "boolean",
    default: true,
    group: "performance",
    description: "Enable continuous batching",
  },
  {
    key: "flash-attn",
    iniKey: "flashAttn",
    label: "Flash Attention",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Enable Flash Attention",
  },
  {
    key: "no-kv-offload",
    iniKey: "noKvOffload",
    label: "No KV Offload",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable KV offload (saves VRAM)",
  },
  {
    key: "cache-type-k",
    iniKey: "cacheTypeK",
    label: "Cache Type K",
    type: "select",
    default: "f16",
    options: ["f16", "q8_0", "q4_0", "q4_1", "q5_0", "q5_1", "q6_K"],
    group: "performance",
    description: "Data type for K cache",
  },
  {
    key: "cache-type-v",
    iniKey: "cacheTypeV",
    label: "Cache Type V",
    type: "select",
    default: "f16",
    options: ["f16", "q8_0", "q4_0", "q4_1", "q5_0", "q5_1", "q6_K"],
    group: "performance",
    description: "Data type for V cache",
  },
  {
    key: "offload-k",
    iniKey: "offloadK",
    label: "Offload K",
    type: "boolean",
    default: true,
    group: "performance",
    description: "Allow offloading K cache",
  },
  {
    key: "offload-v",
    iniKey: "offloadV",
    label: "Offload V",
    type: "boolean",
    default: true,
    group: "performance",
    description: "Allow offloading V cache",
  },
  {
    key: "k-quants",
    iniKey: "kQuants",
    label: "K Quants",
    type: "select",
    default: 0,
    options: [0, 1, 2, 3, 4],
    group: "performance",
    description: "Quantization method for K (0-4)",
  },
  {
    key: "model",
    iniKey: "model",
    label: "Model Path",
    type: "text",
    default: "",
    group: "model",
    description: "Path to model file",
  },
  {
    key: "lora",
    iniKey: "lora",
    label: "LoRA Adapter",
    type: "text",
    default: "",
    group: "model",
    description: "LoRA adapter path (can be repeated)",
  },
  {
    key: "lora-base",
    iniKey: "loraBase",
    label: "LoRA Base",
    type: "text",
    default: "",
    group: "model",
    description: "Optional base LoRA model",
  },
  {
    key: "lora-scaled",
    iniKey: "loraScaled",
    label: "LoRA Scaled",
    type: "text",
    default: "",
    group: "model",
    description: "LoRA with scaling (path:scaling)",
  },
  {
    key: "sdp-attn",
    iniKey: "sdpAttn",
    label: "SDP Attention",
    type: "boolean",
    default: true,
    group: "performance",
    description: "Use SDP attention (disable if needed)",
  },
  {
    key: "no-sse3",
    iniKey: "noSse3",
    label: "No SSE3",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable SSE3 SIMD instructions",
  },
  {
    key: "no-sse4-1",
    iniKey: "noSse41",
    label: "No SSE4.1",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable SSE4.1 SIMD instructions",
  },
  {
    key: "no-avx",
    iniKey: "noAvx",
    label: "No AVX",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable AVX SIMD instructions",
  },
  {
    key: "no-avx2",
    iniKey: "noAvx2",
    label: "No AVX2",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable AVX2 SIMD instructions",
  },
  {
    key: "no-fma",
    iniKey: "noFma",
    label: "No FMA",
    type: "boolean",
    default: false,
    group: "performance",
    description: "Disable FMA SIMD instructions",
  },
];

// Group metadata for UI
const PARAM_GROUPS = {
  core: { label: "Core", icon: "‚öôÔ∏è", order: 1 },
  hardware: { label: "Hardware", icon: "üîß", order: 2 },
  sampling: { label: "Sampling", icon: "üé≤", order: 3 },
  behavior: { label: "Behavior", icon: "üß†", order: 4 },
  context: { label: "Context", icon: "üìù", order: 5 },
  performance: { label: "Performance", icon: "üöÄ", order: 6 },
  speculative: { label: "Speculative", icon: "üîÆ", order: 7 },
  model: { label: "Model", icon: "üì¶", order: 8 },
};

// Export for global use
window.LLAMA_PARAMS = LLAMA_PARAMS;
window.PARAM_GROUPS = PARAM_GROUPS;
