LLAMA_CONFIG_VERSION = 1

[*]
model = 
ctx-size = 89998
threads = 0
temp = 0.7
n-gpu-layers = 0
batch = 512
ubatch = 512

