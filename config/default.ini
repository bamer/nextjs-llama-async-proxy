LLAMA_CONFIG_VERSION = 1

[*]
ubatch-size = 512
ctx-size = 131000
batch-size = 2048
split-mode = row
cache-reuse = 256
tensor-split = 50,30
top-p = 0.9

