import { TooltipContent } from "../tooltip-config.types";

export const samplingAdvancedTooltips: Record<string, TooltipContent> = {
  top_nsigma: {
    title: "Top N Sigma",
    description: "An alternative sampling method that selects tokens within N standard deviations from the mean.",
    recommendedValue: "0 - 3.0 (default: 0)",
    effectOnModel: "When enabled, provides an alternative to Top K/Top P with different distribution characteristics.",
    whenToAdjust: "Use when experimenting with different sampling strategies or standard Top K/Top P don't work well.",
  },
  xtc_probability: {
    title: "XTC Probability",
    description: "Probability of applying XTC (Excluding Top Combinations) sampling to reduce repetition.",
    recommendedValue: "0.0 - 1.0 (default: 0)",
    effectOnModel: "Reduces repetitive token patterns by excluding top combinations with some probability.",
    whenToAdjust: "Enable when the model produces repetitive content or loops.",
  },
  xtc_threshold: {
    title: "XTC Threshold",
    description: "Threshold for XTC sampling, controlling how aggressively to exclude top combinations.",
    recommendedValue: "0.0 - 1.0 (default: 0.1)",
    effectOnModel: "Higher thresholds exclude more top combinations, reducing repetition more aggressively.",
    whenToAdjust: "Adjust based on repetition levels in output.",
  },
  typical_p: {
    title: "Typical P",
    description: "Alternative sampling method that selects tokens based on typicality, filtering out both very high and very low probability tokens.",
    recommendedValue: "0.1 - 1.0 (default: 1.0)",
    effectOnModel: "Produces more natural, typical responses by avoiding both too-predictable and too-unlikely tokens.",
    whenToAdjust: "Use when Top P produces outputs that are either too predictable or too random.",
  },
  dry_multiplier: {
    title: "DRY Multiplier",
    description: "Multiplier for DRY (Don't Repeat Yourself) sampling to penalize repeated n-grams.",
    recommendedValue: "0.0 - 5.0 (default: 0)",
    effectOnModel: "Controls strength of DRY repetition penalty. Higher values reduce repetition more aggressively.",
    whenToAdjust: "Enable when the model repeats phrases or sentences.",
  },
  dry_base: {
    title: "DRY Base",
    description: "Base value for DRY penalty calculation.",
    recommendedValue: "1.0 - 3.0 (default: 1.75)",
    effectOnModel: "Adjusts the base penalty calculation for repeated content.",
    whenToAdjust: "Fine-tune in conjunction with DRY multiplier for optimal repetition control.",
  },
  dry_allowed_length: {
    title: "DRY Allowed Length",
    description: "Minimum length of repeated sequences to apply DRY penalty.",
    recommendedValue: "0 - 10 (default: 2)",
    effectOnModel: "Only penalizes repetitions longer than this value.",
    whenToAdjust: "Increase to allow short repetitions, decrease to catch more repetitions.",
  },
  dry_penalty_last_n: {
    title: "DRY Penalty Last N",
    description: "Number of tokens to look back when applying DRY penalty.",
    recommendedValue: "0 - 512 (default: 0)",
    effectOnModel: "Controls the context window for DRY repetition detection.",
    whenToAdjust: "Increase to detect longer-range repetitions.",
  },
  dry_sequence_breaker: {
    title: "DRY Sequence Breaker",
    description: "Characters that break sequences for DRY penalty calculation.",
    recommendedValue: "\\n, !, ., ? (default: \\n, !, ., ?)",
    effectOnModel: "Separates text into chunks at these characters when detecting repetitions.",
    whenToAdjust: "Customize based on language and text structure.",
  },
  dynatemp_range: {
    title: "Dynatemp Range",
    description: "Range for dynamic temperature adjustment during generation.",
    recommendedValue: "0.0 - 2.0 (default: 0)",
    effectOnModel: "Enables temperature to vary dynamically within this range for more varied outputs.",
    whenToAdjust: "Enable when you want varied creativity throughout the response.",
  },
  dynatemp_exponent: {
    title: "Dynatemp Exponent",
    description: "Exponent for dynamic temperature curve shape.",
    recommendedValue: "0.1 - 2.0 (default: 1)",
    effectOnModel: "Controls the distribution shape of dynamic temperature values.",
    whenToAdjust: "Fine-tune with dynatemp_range for desired dynamic behavior.",
  },
  mirostat: {
    title: "Mirostat",
    description: "Enables Mirostat algorithm for constant perplexity sampling. 0=off, 1=Mirostat, 2=Mirostat 2.0.",
    recommendedValue: "0, 1, or 2 (default: 0)",
    effectOnModel: "Maintains constant perplexity for more consistent text quality. Mirostat 2.0 is more advanced.",
    whenToAdjust: "Use when you need consistently high-quality output with controlled perplexity.",
  },
  mirostat_eta: {
    title: "Mirostat Eta (Learning Rate)",
    description: "Learning rate (eta) for Mirostat algorithm.",
    recommendedValue: "0.001 - 1.0 (default: 0.1)",
    effectOnModel: "Controls how quickly Mirostat adapts to maintain target perplexity.",
    whenToAdjust: "Adjust based on how quickly you want the algorithm to adapt.",
  },
  mirostat_tau: {
    title: "Mirostat Tau (Target Entropy)",
    description: "Target entropy (tau) for Mirostat algorithm.",
    recommendedValue: "0.0 - 10.0 (default: 5)",
    effectOnModel: "Sets the target perplexity/entropy for text generation.",
    whenToAdjust: "Lower for more focused text, higher for more diverse text.",
  },
  samplers: {
    title: "Samplers",
    description: "List of samplers to use, in order.",
    recommendedValue: "e.g., y_root, temp, top_p, top_k",
    effectOnModel: "Controls which sampling methods are applied and in what sequence.",
    whenToAdjust: "Customize for specific sampling strategies.",
  },
  sampler_seq: {
    title: "Sampler Sequence",
    description: "Alternative way to specify sampler order.",
    recommendedValue: "e.g., 0,1,2,3",
    effectOnModel: "Same as samplers but uses numeric IDs.",
    whenToAdjust: "Use when you prefer numeric sampler specification.",
  },
  grammar: {
    title: "Grammar",
    description: "Grammar string in GBNF format to constrain output format.",
    recommendedValue: "Custom GBNF grammar",
    effectOnModel: "Forces output to conform to specified grammar (JSON, code formats, etc.)",
    whenToAdjust: "Use when you need structured output like JSON, code, or specific formats.",
  },
  grammar_file: {
    title: "Grammar File",
    description: "Path to a file containing GBNF grammar rules.",
    recommendedValue: "File path",
    effectOnModel: "Loads grammar from file instead of inline string.",
    whenToAdjust: "Use for complex grammars stored in files.",
  },
  json_schema: {
    title: "JSON Schema",
    description: "JSON schema to constrain output to valid JSON.",
    recommendedValue: "Valid JSON schema",
    effectOnModel: "Ensures output matches specified JSON schema.",
    whenToAdjust: "Use when you need JSON output with specific structure.",
  },
  json_schema_file: {
    title: "JSON Schema File",
    description: "Path to a file containing JSON schema.",
    recommendedValue: "File path",
    effectOnModel: "Loads JSON schema from file.",
    whenToAdjust: "Use for schemas stored in files.",
  },
  ignore_eos: {
    title: "Ignore EOS",
    description: "Whether to ignore end-of-sequence tokens. 0=off, 1=on.",
    recommendedValue: "0 or 1 (default: 0)",
    effectOnModel: "When enabled, model won't stop at EOS tokens, continuing generation.",
    whenToAdjust: "Enable when you want longer outputs beyond natural stopping points.",
  },
  escape: {
    title: "Escape",
    description: "Enables special character escaping in output.",
    recommendedValue: "false or true (default: false)",
    effectOnModel: "Affects how special characters are handled in output.",
    whenToAdjust: "Use when working with special characters or escape sequences.",
  },
};
