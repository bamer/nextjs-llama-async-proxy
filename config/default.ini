LLAMA_CONFIG_VERSION = 1

[*]
ctx-size = 131000
batch-size = 2048
ubatch-size = 512
top-p = 0.95
seed = 2
cache-reuse = 64
main-gpu = 1
split-mode = row
warmup = off

[gemma-3-1b-it-Q4_K_M]
ctx-size = 64840

[nvidia_Nemotron-3-Nano-30B-A3B-Q5_K_L]

[HY-MT1.5-1.8B.Q8_0]

[Ministral-3-14B-Reasoning-2512-Q4_1]

[Youtu-LLM-2B-F16]

