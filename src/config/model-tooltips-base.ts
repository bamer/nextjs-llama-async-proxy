import { TooltipContent } from "./tooltip-config.types";

export const samplingTooltips: Record<string, TooltipContent> = {
  temperature: {
    title: "Temperature",
    description: "Controls randomness in token selection. Higher values make output more random and creative, lower values make it more deterministic and focused.",
    recommendedValue: "0.0 - 2.0 (default: 0.7)",
    effectOnModel: "Higher values (≥1.0) increase creativity but may reduce coherence. Lower values (≤0.5) produce more predictable, focused responses.",
    whenToAdjust: "Increase for creative writing or brainstorming. Decrease for code generation, factual responses, or when you need precise outputs.",
  },
  top_k: {
    title: "Top K",
    description: "Limits token sampling to K most likely tokens. Prevents model from selecting from very low probability tokens.",
    recommendedValue: "1 - 100 (default: 40)",
    effectOnModel: "Lower values (1-10) restrict output to very likely tokens, reducing diversity. Higher values (40-100) allow more varied vocabulary.",
    whenToAdjust: "Use lower values for more deterministic outputs. Increase when model is too repetitive or needs more vocabulary variety.",
  },
  top_p: {
    title: "Top P (Nucleus Sampling)",
    description: "Nucleus sampling: samples from the smallest set of tokens whose cumulative probability exceeds P. Works with Top K to control diversity.",
    recommendedValue: "0.1 - 1.0 (default: 0.9)",
    effectOnModel: "Lower values (0.1-0.5) create more focused, less diverse outputs. Higher values (0.8-1.0) allow more creative, varied responses.",
    whenToAdjust: "Decrease for more focused, predictable outputs. Increase for creative tasks where variety is desired.",
  },
  min_p: {
    title: "Min P",
    description: "Sets a minimum probability threshold for token selection. Tokens below this probability are excluded.",
    recommendedValue: "0.0 - 0.5 (default: 0.05)",
    effectOnModel: "Filters out very low probability tokens, reducing generation of nonsensical content.",
    whenToAdjust: "Increase to filter out more low-probability tokens and improve output quality.",
  },
  top_nsigma: {
    title: "Top N Sigma",
    description: "An alternative sampling method that selects tokens within N standard deviations from mean.",
    recommendedValue: "0 - 3.0 (default: 0)",
    effectOnModel: "When enabled, provides an alternative to Top K/Top P with different distribution characteristics.",
    whenToAdjust: "Use when experimenting with different sampling strategies or standard Top K/Top P don't work well.",
  },
  xtc_probability: {
    title: "XTC Probability",
    description: "Probability of applying XTC (Excluding Top Combinations) sampling to reduce repetition.",
    recommendedValue: "0.0 - 1.0 (default: 0)",
    effectOnModel: "Reduces repetitive token patterns by excluding top combinations with some probability.",
    whenToAdjust: "Enable when model produces repetitive content or loops.",
  },
  xtc_threshold: {
    title: "XTC Threshold",
    description: "Threshold for XTC sampling, controlling how aggressively to exclude top combinations.",
    recommendedValue: "0.0 - 1.0 (default: 0.1)",
    effectOnModel: "Higher thresholds exclude more top combinations, reducing repetition more aggressively.",
    whenToAdjust: "Adjust based on repetition levels in output.",
  },
  typical_p: {
    title: "Typical P",
    description: "Alternative sampling method that selects tokens based on typicality, filtering out both very high and very low probability tokens.",
    recommendedValue: "0.1 - 1.0 (default: 1.0)",
    effectOnModel: "Produces more natural, typical responses by avoiding both too-predictable and too-unlikely tokens.",
    whenToAdjust: "Use when Top P produces outputs that are either too predictable or too random.",
  },
  repeat_last_n: {
    title: "Repeat Last N",
    description: "Number of last tokens to consider when applying repeat penalties.",
    recommendedValue: "0 - 2048 (default: 64)",
    effectOnModel: "Controls the sliding window for detecting repeated patterns. Larger windows catch more distant repetitions.",
    whenToAdjust: "Increase to detect longer-range repetitions. Decrease for short-term repetition control.",
  },
  repeat_penalty: {
    title: "Repeat Penalty",
    description: "Applies a penalty to tokens that appear in recent context, reducing repetition.",
    recommendedValue: "1.0 - 2.0 (default: 1.0)",
    effectOnModel: "Values >1.0 penalize repeated tokens, reducing loops. 1.0 disables penalty. Too high values can break flow.",
    whenToAdjust: "Increase when model repeats itself. Decrease if output becomes unnatural or fragmented.",
  },
  presence_penalty: {
    title: "Presence Penalty",
    description: "Penalizes tokens that have already appeared at all in the generated text, encouraging variety.",
    recommendedValue: "0.0 - 2.0 (default: 0)",
    effectOnModel: "Encourages the model to talk about new topics and vocabulary. Too high can make responses incoherent.",
    whenToAdjust: "Use to encourage diverse vocabulary and avoid stuck topics.",
  },
  frequency_penalty: {
    title: "Frequency Penalty",
    description: "Penalizes tokens based on how frequently they've appeared, not just presence.",
    recommendedValue: "0.0 - 2.0 (default: 0)",
    effectOnModel: "More aggressive than presence penalty, heavily penalizing frequently used words.",
    whenToAdjust: "When presence penalty isn't enough to reduce word repetition.",
  },
  mirostat: {
    title: "Mirostat",
    description: "Enables Mirostat algorithm for constant perplexity sampling. 0=off, 1=Mirostat, 2=Mirostat 2.0.",
    recommendedValue: "0, 1, or 2 (default: 0)",
    effectOnModel: "Maintains constant perplexity for more consistent text quality. Mirostat 2.0 is more advanced.",
    whenToAdjust: "Use when you need consistently high-quality output with controlled perplexity.",
  },
  mirostat_eta: {
    title: "Mirostat Eta (Learning Rate)",
    description: "Learning rate (eta) for Mirostat algorithm.",
    recommendedValue: "0.001 - 1.0 (default: 0.1)",
    effectOnModel: "Controls how quickly Mirostat adapts to maintain target perplexity.",
    whenToAdjust: "Adjust based on how quickly you want the algorithm to adapt.",
  },
  mirostat_tau: {
    title: "Mirostat Tau (Target Entropy)",
    description: "Target entropy (tau) for Mirostat algorithm.",
    recommendedValue: "0.0 - 10.0 (default: 5)",
    effectOnModel: "Sets the target perplexity/entropy for text generation.",
    whenToAdjust: "Lower for more focused text, higher for more diverse text.",
  },
  samplers: {
    title: "Samplers",
    description: "List of samplers to use, in order.",
    recommendedValue: "e.g., y_root, temp, top_p, top_k",
    effectOnModel: "Controls which sampling methods are applied and in what sequence.",
    whenToAdjust: "Customize for specific sampling strategies.",
  },
  sampler_seq: {
    title: "Sampler Sequence",
    description: "Alternative way to specify sampler order.",
    recommendedValue: "e.g., 0,1,2,3",
    effectOnModel: "Same as samplers but uses numeric IDs.",
    whenToAdjust: "Use when you prefer numeric sampler specification.",
  },
  seed: {
    title: "Seed",
    description: "Random seed for generation. -1 uses random seed.",
    recommendedValue: "-1 or positive integer (default: -1)",
    effectOnModel: "Same seed with same settings produces identical output.",
    whenToAdjust: "Set for reproducible outputs during testing or debugging.",
  },
  grammar: {
    title: "Grammar",
    description: "Grammar string in GBNF format to constrain output format.",
    recommendedValue: "Custom GBNF grammar",
    effectOnModel: "Forces output to conform to specified grammar (JSON, code formats, etc.)",
    whenToAdjust: "Use when you need structured output like JSON, code, or specific formats.",
  },
  grammar_file: {
    title: "Grammar File",
    description: "Path to a file containing GBNF grammar rules.",
    recommendedValue: "File path",
    effectOnModel: "Loads grammar from file instead of inline string.",
    whenToAdjust: "Use for complex grammars stored in files.",
  },
  json_schema: {
    title: "JSON Schema",
    description: "JSON schema to constrain output to valid JSON.",
    recommendedValue: "Valid JSON schema",
    effectOnModel: "Ensures output matches specified JSON schema.",
    whenToAdjust: "Use when you need JSON output with specific structure.",
  },
  json_schema_file: {
    title: "JSON Schema File",
    description: "Path to a file containing JSON schema.",
    recommendedValue: "File path",
    effectOnModel: "Loads JSON schema from file.",
    whenToAdjust: "Use for schemas stored in files.",
  },
  ignore_eos: {
    title: "Ignore EOS",
    description: "Whether to ignore end-of-sequence tokens. 0=off, 1=on.",
    recommendedValue: "0 or 1 (default: 0)",
    effectOnModel: "When enabled, model won't stop at EOS tokens, continuing generation.",
    whenToAdjust: "Enable when you want longer outputs beyond natural stopping points.",
  },
  escape: {
    title: "Escape",
    description: "Enables special character escaping in output.",
    recommendedValue: "false or true (default: false)",
    effectOnModel: "Affects how special characters are handled in output.",
    whenToAdjust: "Use when working with special characters or escape sequences.",
  },
};
