import { createServer } from 'http';
import next from 'next';
import { Server } from 'socket.io';
import express from 'express';
import LlamaServerIntegration from './src/server/services/LlamaServerIntegration.ts';
import { registry } from './src/server/ServiceRegistry.ts';
import { loadConfig } from './src/lib/server-config.ts';
import { setSocketIOInstance, getLogger } from './src/lib/logger.ts';

const logger = getLogger();

const dev = process.env.NODE_ENV !== 'production';
const app = next({ dev });
const nextHandler = app.getRequestHandler()
const hostname = 'localhost';
const port = process.env.PORT ? parseInt(process.env.PORT, 10) : 3000;

// Make registry available globally for API routes
global.registry = registry;

logger.info('üöÄ [SOCKET.IO] Initializing Socket.IO server...');

app.prepare().then(() => {
  logger.info('‚úÖ [SOCKET.IO] Next.js app prepared, starting HTTP server...');

  const expressApp = express();
  const server = createServer(expressApp);

  const io = new Server(server, {
    cors: {
      origin: '*',
      methods: ['GET', 'POST'],
      allowedHeaders: ['Content-Type', 'Authorization']
    },
    connectionStateRecovery: {
      maxDisconnectionDuration: 2 * 60 * 1000,
      skipMiddlewares: true,
    },
    path: '/llamaproxws',
    pingTimeout: 60000,
    pingInterval: 25000,
    maxHttpBufferSize: 1e8,
    transports: ['websocket'],
  });

  logger.info('üîß [SOCKET.IO] Socket.IO server configured with path: /llamaproxws');

  // Set Socket.IO instance in Winston logger for real-time log streaming
  setSocketIOInstance(io);
  logger.info('üîß [LOGGER] Socket.IO instance registered for WebSocket transport');

  const llamaIntegration = new LlamaServerIntegration(io);

  const clients = new Map();

  io.on('connection', (socket) => {
    const clientId = socket.id;
    clients.set(clientId, socket);

    logger.info(`üîå [SOCKET.IO] New client connected (ID: ${clientId}) - Total clients: ${clients.size}`);

    socket.emit('message', {
      type: 'connection',
      clientId,
      message: 'Connected to Socket.IO server',
      timestamp: new Date().toISOString()
    });

    llamaIntegration.setupWebSocketHandlers(socket);

    socket.on('message', (data) => {
      try {
        logger.info(`üí¨ [SOCKET.IO] Message received: ${data.type || 'unknown'}`);
        socket.broadcast.emit('message', data);
      } catch (error) {
        logger.error(`‚ùå [SOCKET.IO] Error processing message: ${error.message}`);
      }
    });

    socket.on('disconnect', (reason) => {
      logger.info(`üî¥ [SOCKET.IO] Client disconnected (ID: ${clientId}) | Reason: ${reason} - Remaining clients: ${clients.size - 1}`);
      clients.delete(clientId);
    });

    socket.on('connect_error', (error) => {
      logger.error(`‚ùå [SOCKET.IO] Connection error for client ${clientId}: ${error.message}`);
    });
  });

  expressApp.use((req, res) => {
    return nextHandler(req, res)
  });

  server.listen(port, async (err) => {
    if (err) throw err
    logger.info(`> Ready on http://${hostname}:${port}`);
    logger.info(`üöÄ [SOCKET.IO] Server listening at http://${hostname}:${port}`);
    logger.info('üöÄ [SOCKET.IO] Socket.IO server is ready');

    // Load configuration from llama-server-config.json
    let llamaConfig;
    try {
      const loadedConfig = loadConfig();
      llamaConfig = {
        host: process.env.LLAMA_SERVER_HOST || loadedConfig.host,
        port: parseInt(process.env.LLAMA_SERVER_PORT || String(loadedConfig.port), 10),
        basePath: process.env.MODELS_PATH || loadedConfig.basePath,
        serverPath: loadedConfig.serverPath,
        ctx_size: loadedConfig.ctx_size,
        batch_size: loadedConfig.batch_size,
        threads: loadedConfig.threads,
        gpu_layers: loadedConfig.gpu_layers,
      };
      logger.info('üìù [CONFIG] Configuration loaded from llama-server-config.json');
    } catch (error) {
      logger.warn(`‚ö†Ô∏è [CONFIG] Failed to load config file, using defaults: ${error.message}`);
      llamaConfig = {
        host: process.env.LLAMA_SERVER_HOST || 'localhost',
        port: parseInt(process.env.LLAMA_SERVER_PORT || '8134', 10),
        basePath: process.env.MODELS_PATH || '/models',
        serverPath: '/home/bamer/llama.cpp/build/bin/llama-server',
        ctx_size: 8192,
        batch_size: 512,
        threads: -1,
        gpu_layers: -1,
      };
    }

    try {
      logger.info('ü¶ô Initializing LlamaServer integration...');
      logger.info(`üìã [CONFIG] Llama server path: ${llamaConfig.serverPath}`);
      logger.info(`üìã [CONFIG] Host: ${llamaConfig.host}:${llamaConfig.port}`);
      logger.info(`üìã [CONFIG] Base path: ${llamaConfig.basePath}`);
      await llamaIntegration.initialize(llamaConfig);

      registry.register('llamaService', llamaIntegration.getLlamaService());
      logger.info('‚úÖ LlamaServer integration initialized successfully');
    } catch (error) {
      logger.error(`‚ùå Failed to initialize LlamaServer integration: ${error.message}`);
      logger.warn('‚ö†Ô∏è Server will continue running, but model management may not work');
    }
  });

  server.on('error', (error) => {
    logger.error(`‚ùå [SOCKET.IO] HTTP Server error: ${error.message}`);
    if (error.code === 'EADDRINUSE') {
      logger.error(`üî• [SOCKET.IO] Port ${port} is already in use!`);
    }
  });

  io.engine.on('connection_error', (err) => {
    logger.error(`‚ùå [SOCKET.IO] Connection error: ${err.message}`);
  });

  const cleanup = async () => {
    logger.info('üëã [SHUTDOWN] Starting graceful shutdown...');
    io.disconnectSockets();
    await llamaIntegration.stop();
    server.close(() => {
      logger.info('üëã [SHUTDOWN] Server shutdown complete');
      process.exit(0);
    });
  };

process.on('SIGTERM', cleanup);
process.on('SIGINT', cleanup);
process.on('exit', (code) => {
  logger.info(`üëã [SHUTDOWN] Server exited with code ${code}`);
});

process.on('uncaughtException', (error) => {
  logger.error('‚ùå [UNCAUGHT EXCEPTION]', error);
  cleanup();
});

process.on('unhandledRejection', (reason, promise) => {
  logger.error('‚ùå [UNHANDLED REJECTION]', reason);
  cleanup();
});

  process.on('SIGTERM', cleanup);
  process.on('SIGINT', cleanup);

}).catch((error) => {
  logger.error(`‚ùå [SOCKET.IO] Failed to prepare Next.js app: ${error.message}`);
  process.exit(1);
});
