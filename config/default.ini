LLAMA_CONFIG_VERSION = 1

[*]
ubatch-size = 512
ctx-size = 131000
batch-size = 2048
split-mode = row
cache-reuse = 64
tensor-split = 50,50
top-p = 0.95
seed = 2
temperature = 0.7
main-gpu = 1

[gemma-3-1b-it-Q4_K_M]
ctx-size = 0

