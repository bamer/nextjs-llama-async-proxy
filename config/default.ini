LLAMA_CONFIG_VERSION = 1

[*]
ctx-size = 2048
temp = 0.7

[llama-2-13b]
model = /path/to/llama-2-13b.gguf
ctx-size = 4096
n-gpu-layers = 20

[fluentlyqwen3-coder-4b-q8_0.gguf]
model = /media/bamer/crucial MX300/llm/llama/models/fluentlyqwen3-coder-4b-q8_0-gguf/fluentlyqwen3-coder-4b-q8_0.gguf

